---
title: "4. Análise do efeito dos ECEs sobre a agenda"
output: html_notebook
---

# 4. Análise do efeito dos ECEs sobre a agenda

Agora que já identificamos quais os tópicos dos documentos, vamos fazer uma análise da produção em relação ao total da produção.\
\
Na primeira, faremos a análise com toda a produção que menciona os termos procurados. Na segunda, vamos nos restringir à produção em projetos de lei

## Pacotes e bases de dado

```{r}
#install.packages("viridis")
#install.packages("plm")
```

```{r, echo = FALSE, warning=FALSE}
library(dplyr)
library(here)
library(tidyr)
library(data.table)
library(stringr)
library(ggplot2)
library(lubridate)
library(viridis)
options(digits=5)
```

```{r, echo = FALSE}
df_ols <- readRDS(here("Dados/df_ols.RDS")) %>% 
  mutate(Dia = as.integer(Dia)) #Corrigindo Dia como integral
```

## 4.1 Observando as características da série

### 4.1.1 Distribuição da agenda climática

```{r}

#Heatmap
heatmap <- df_ols %>% 
  mutate(Regiao = str_sub(Cod_IBGE_Mun, 1, 1)) %>% 
  ggplot(aes(x = Data, y = Cod_IBGE_Mun)) +
  geom_tile(aes(fill = agenda_clima)) +   
  geom_tile(data = df_ols[df_ols$Desastre == 1, ], 
            aes(fill = NULL), 
            color = "red") +  
  scale_fill_viridis() +
  theme_classic() +
  theme(legend.position = "top") +
  labs(title = "Distribuição da apresentação de projetos, por município e data",
       y = "Código IBGE do Município", 
       x = "Data", 
       fill = "Percentual de projetos climáticos apresentados")
  
heatmap

ggsave(here("Figuras/4.1.1Heatmap_projetos_climaticos.png"), heatmap, height = 30, width = 10)

rm(heatmap)
```

## 4.2 Testando as condições da variável destino para análise de séries temporais

### 4.2.1 Analisando a existência de tendências na variável destino

```{r}
#Subindo pacotes de análise de séries temporais: 

library(plm)

df_ols <- pdata.frame(df_ols, index = c("Cod_IBGE_Mun", "Dia"))%>% 
  mutate(Dia = as.integer(Dia)) #Corrigindo Dia como integral

TesteTend <- lm(agenda_clima ~ Dia, data = df_ols)

summary(TesteTend)

rm(TesteTend)
```

Existe uma linha de tendência significativa, mas de magnitude pequena

### 4.2.2 Testes de autocorrelação serial (raiz unitária)

```{r}
# Teste de Breusch-Godfrey com "pbgtest"


TesteBG <- pbgtest(agenda_clima ~ lag(agenda_clima), data = df_ols)


TesteBG

rm(TesteBG)
```

O resultado sugere que não há autocorrelação serial significativa na série temporal analisada.

### 4.2.3 Testes de sazonalidade

```{r}

sazonalidade <- df_ols %>% 
  group_by(Mes, Cod_IBGE_Mun) %>% 
  summarise(n_proj_clima = sum(n_proj_clima), 
            total_proj_mes = sum(total_proj_dia), 
            agenda_clima = n_proj_clima/total_proj_mes) %>% 
  mutate(agenda_clima = ifelse(agenda_clima == "NaN", 0, agenda_clima)) %>% 
  group_by(Mes) %>% 
  summarise(agenda_clima = mean(agenda_clima)) %>% 
  ggplot(aes(x = Mes, y = agenda_clima)) +
  geom_col(fill = "darkgreen")+
  theme_bw()+
  labs(title = "Percentual médio de produção legislativa relacionada ao clima, por mês",
       x= "Mês", 
       y = "Percentual de produção legislativa")+
  scale_x_continuous(n.breaks = 12)


sazonalidade

rm(sazonalidade)
```

Como é possível observar, há um aumento do percentual de produção em políticas climáticas nos meses de verão,, em especial fevereiro e março, e uma queda considerável em dezembro.

### 4.2.4 Checando por autocorrelação nas variáveis

```{r}
#Checando por autocorrelações na matriz das variáveis: 

cor_matrix <- cor(df_ols[, c("agenda_clima", "Desastre", "Obitos",
                             "dias_proxima_eleicao", "Receitas_pCap", "n_OSCs",
                             "AB2_Recursos_Hídricos_Seca", 
                             "AB2_Segurança_Alimentar_Seca", "AB2_Segurança_Alimentar_Chuva",
                             "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos",
                             "AB2_Desastres_Hidrológicos_Deslizamento_de_terra")],
                  use = "complete.obs") %>% 
  data.table() %>% 
  mutate(Coluna = c("agenda_clima", "Desastre", "Obitos",
                             "dias_proxima_eleicao", "Receitas_pCap", "n_OSCs",
                             "AB2_Recursos_Hídricos_Seca", 
                             "AB2_Segurança_Alimentar_Seca", "AB2_Segurança_Alimentar_Chuva",
                             "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos",
                             "AB2_Desastres_Hidrológicos_Deslizamento_de_terra")) 
correlacao1 <- cor_matrix %>% 
  pivot_longer(cols = 1:(length(cor_matrix)-1), names_to = "Linha", values_to = "Valores") %>% 
  ggplot(aes(x= Linha, y = Coluna, fill = Valores)) + 
  geom_tile()

correlacao1

rm(cor_matrix, correlacao1)
```

Como é possível observar, a maioria das variáveis não tem um nível de correlação muito elevado, exceto as da mesma categoria do Índice de Risco Climático.

```{r}
#Checando missing values:

colSums(is.na(df_ols))

Receitas_NA <- df_ols %>% 
  filter(is.na(Receitas_pCap)) %>% 
  group_by(Cod_IBGE_Mun) %>% 
  summarise()
```

Como é possível observar, temos 14 cidades com Missing Values para a receita. Estes municípios terão que ser removidos da seleção para fazer a análise.\

## 4.3 Rodando a regressão com série temporal

### 4.3.1 Análise com todas as variáveis - Modelo Pooling

```{r}
#Preparando base de dados 
df_ols <- df_ols %>% 
  filter(!Cod_IBGE_Mun %in% Receitas_NA$Cod_IBGE_Mun) %>% #remove municípios incompletos 
  pdata.frame(index = c("Cod_IBGE_Mun", "Dia"))

rm(Receitas_NA)
```

### Modelo 1: Pooling

```{r}
library(stargazer)

#Primeito modelo: agenda mensurada como percentual com menção a termos climáticos

modelo1 <- plm(agenda_clima ~ lag(agenda_clima)+
                 Desastre + lag(Desastre) + Obitos + lag(Obitos) + 
                 dias_proxima_eleicao +  
                 Receitas_pCap + n_OSCs +
                 AB2_Recursos_Hídricos_Seca + 
                 AB2_Segurança_Alimentar_Seca + AB2_Segurança_Alimentar_Chuva +                AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos + AB2_Desastres_Hidrológicos_Deslizamento_de_terra, 
               data = df_ols, model = "pooling", pooling = T)

stargazer(modelo1, type = "text")
```

### Visualizando os resultados

```{r}
# Extrair coeficientes e erros padrão diretamente do objeto plm
coefs <- modelo1$coefficients
variaveis <- names(coefs)
estimativas <- coefs

# Extrair erros padrão da matriz de variâncias-covariâncias
erros_padrao <- sqrt(diag(modelo1$vcov))

# Calcular p-valores (opcional, com base na distribuição normal)
t_values <- estimativas / erros_padrao
pvalores <- 1.96 * (1 - pnorm(abs(t_values)))

# Definir nível de significância
nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                 labels = c("***", "**", "*", ".", " "))

# Construir data.frame
m1_plot <- data.frame(
  Variavel = factor(variaveis, levels = variaveis), # manter a ordem
  Estimativa = estimativas,
  Erro_Padrao = erros_padrao,
  IC_inferior = estimativas - 1.96 * erros_padrao,
  IC_superior = estimativas + 1.96 * erros_padrao,
  Significancia = nivel_sig
)

# Remover intercepto para focar nos preditores
#m1_plot <- subset(m1_plot, Variavel != "(Intercept)")

# Plot com ggplot2
M1plot <- ggplot(m1_plot, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  geom_hline(yintercept = 0, color = "black") +
  scale_color_manual(values = c("***"="#6E0000", "**"="#CB8400", "*"="#FFD028", "."="#F7FF00", " "="gray"),
                     name = "Nível de\nSignificância") +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "bottom")+
  labs(
    title = "Modelo 1 - Coeficientes (95%)",
    x = "Variável",
    y = "Estimativa"
  )

M1plot

rm(coefs, variaveis, estimativas, erros_padrao, t_values, pvalores, nivel_sig, M1plot, m1_plot)
```

### Teste de autocorrelação nas unidades (Pesaran)

```{r}

TestePesaran1 <- pcdtest(modelo1, test = "cd")
print(TestePesaran1)

rm(TestePesaran1)
```

### Teste de autocorrelação serial de Durbin-Watson

```{r}
#Teste de Durbin-Watson:
TesteDW1 <- pdwtest(modelo1)

print(TesteDW1)

rm(TesteDW1, modelo1)
```

### 4.3.2 - Modelo "Within"

```{r}
#Segunda modelo: agenda mensurada como percentual com menção a termos climáticos, dentro dos municípios

modelo2 <- plm(agenda_clima ~ lag(agenda_clima)+
                 Desastre + lag(Desastre) + Obitos + lag(Obitos) + 
                 dias_proxima_eleicao +  
                 Receitas_pCap + n_OSCs +
                 AB2_Recursos_Hídricos_Seca + 
                 AB2_Segurança_Alimentar_Seca + AB2_Segurança_Alimentar_Chuva +                AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos + AB2_Desastres_Hidrológicos_Deslizamento_de_terra, 
               data = df_ols, model = "within")

stargazer(modelo2, type = "text")
```

### Visualizando os resultados

```{r}
# Extrair coeficientes e erros padrão diretamente do objeto plm
coefs <- modelo2$coefficients
variaveis <- names(coefs)
estimativas <- coefs

# Extrair erros padrão da matriz de variâncias-covariâncias
erros_padrao <- sqrt(diag(modelo2$vcov))

# Calcular p-valores (opcional, com base na distribuição normal)
t_values <- estimativas / erros_padrao
pvalores <- 1.96 * (1 - pnorm(abs(t_values)))

# Definir nível de significância
nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                 labels = c("***", "**", "*", ".", " "))

# Construir data.frame
m2_plot <- data.frame(
  Variavel = factor(variaveis, levels = variaveis), # manter a ordem
  Estimativa = estimativas,
  Erro_Padrao = erros_padrao,
  IC_inferior = estimativas - 1.96 * erros_padrao,
  IC_superior = estimativas + 1.96 * erros_padrao,
  Significancia = nivel_sig
)

# Remover intercepto para focar nos preditores
#m1_plot <- subset(m1_plot, Variavel != "(Intercept)")

# Plot com ggplot2
M2plot <- ggplot(m2_plot, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  geom_hline(yintercept = 0, color = "black") +
  scale_color_manual(values = c("***"="#6E0000", "**"="#CB8400", "*"="#FFD028", "."="#F7FF00", " "="gray"),
                     name = "Nível de\nSignificância") +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "bottom")+
  labs(
    title = "Modelo 1 - Coeficientes (95%)",
    x = "Variável",
    y = "Estimativa"
  )

M2plot

rm(coefs, variaveis, estimativas, erros_padrao, t_values, pvalores, nivel_sig, M2plot, m2_plot)
```

### Teste de autocorrelação nas unidades (Pesaran)

```{r}

TestePesaran2 <- pcdtest(modelo2, test = "cd")
print(TestePesaran2)

rm(TestePesaran2)
```

### Teste de autocorrelação serial de Durbin-Watson

```{r}
#Teste de Durbin-Watson:
TesteDW2 <- pdwtest(modelo2)

print(TesteDW2)

rm(TesteDW2, modelo2)
```

## 4.4 Teste com agenda climática estrita

Agora, vamos repetir a análise, utilizando apenas os projetos identificados na segunda modelagem de tópicos como condizentes com a agenda em adaptação climática.

```{r}
df_stm <- readRDS(here("Dados/df_STM_PL.RDS")) %>% 
  filter(!topico_principalPL %in% c("Tópico PL1", "Tópico PL5", "Tópico PL6", "Tópico PL7", "Tópico PL8")) %>% #Removendo tópicos que não dizem respeito à política climática
  group_by(Data, Cod_IBGE_Mun) %>% 
  summarise(N_PLsClima = n( ),
            Total_PLs = sum(total_tipo_proj_dia)) %>% 
  mutate(PL_agendaclima = N_PLsClima/Total_PLs)

#Juntando à outra base e completando as informações que faltam
df_stm <- merge(df_ols, df_stm, by = c("Data", "Cod_IBGE_Mun"), all.x = T) %>% 
  mutate(N_PLsClima = ifelse(is.na(N_PLsClima), 0, N_PLsClima),
         PL_agendaclima = ifelse(is.na(PL_agendaclima), 0, PL_agendaclima))%>% 
  mutate(Ano_Mes = paste0(Ano, "-", Mes)) %>% 
  group_by(Ano_Mes, Cod_IBGE_Mun, Ano, Mes, Receitas_pCap, AB2_Recursos_Hídricos_Seca, AB2_Segurança_Alimentar_Seca, AB2_Segurança_Alimentar_Chuva,       AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos, AB2_Desastres_Hidrológicos_Deslizamento_de_terra) %>% 
  summarise(N_PLsClima = sum(N_PLsClima),
            Total_PLs = sum(Total_PLs),
            Desastre = sum(Desastre),
            Obitos = sum(Obitos),
            n_OSCs = max(n_OSCs),
            eleicao = sum(eleicao),
            total_proj_dia = sum(total_proj_dia))
```

```{r}
#Heatmap2
heatmap2 <- df_stm %>% 
  mutate(Regiao = str_sub(Cod_IBGE_Mun, 1, 1)) %>% 
  ggplot(aes(x = Ano_Mes, y = Cod_IBGE_Mun)) +
  geom_tile(aes(fill = N_PLsClima)) +   
  geom_tile(data = df_stm[df_stm$Desastre == 1, ], 
            aes(fill = NULL), 
            color = "red") +  
  theme_classic() +
  theme(legend.position = "top") +
  labs(title = "Distribuição da apresentação de projetos, por município e data",
       y = "Código IBGE do Município", 
       x = "Data", 
       fill = "Número de projetos climáticos apresentados")
  
heatmap2

ggsave(here("Figuras/4.4.1Heatmap_NPlsClima.png"), heatmap2, height = 30, width = 10)

rm(heatmap2)
```

### 4.4.3 Testes de sazonalidade

```{r}

sazonalidade2 <- df_stm %>% 
  group_by(Cod_IBGE_Mun, Mes) %>% 
  summarise(N_PLsClima = sum(N_PLsClima)) %>% 
  group_by(Mes) %>% 
  summarise(N_PLsClima = mean(N_PLsClima)) %>% 
  ggplot(aes(x = Mes, y = N_PLsClima)) +
  geom_col(fill = "darkgreen")+
  theme_bw()+
  labs(title = "Média de produção legislativa relacionada ao clima, por mês",
       x= "Mês", 
       y = "Percentual de produção legislativa")+
  scale_x_continuous(n.breaks = 12)

sazonalidade2

rm(sazonalidade2)
```

### PAREI AQUI 4.4.4 Checando por autocorrelação nas variáveis

```{r}
#Checando por autocorrelações na matriz das variáveis: 

cor_matrix <- cor(df_stm[, c("N_PLsClima", "Desastre", "Obitos",
                             "eleicao", "Receitas_pCap", "n_OSCs",
                             "AB2_Recursos_Hídricos_Seca", 
                             "AB2_Segurança_Alimentar_Seca", "AB2_Segurança_Alimentar_Chuva",
                             "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos",
                             "AB2_Desastres_Hidrológicos_Deslizamento_de_terra")],
                  use = "complete.obs") %>% 
  data.table() %>% 
  mutate(Coluna = c("N_PLsClima", "Desastre", "Obitos",
                             "eleicao", "Receitas_pCap", "n_OSCs",
                             "AB2_Recursos_Hídricos_Seca", 
                             "AB2_Segurança_Alimentar_Seca", "AB2_Segurança_Alimentar_Chuva",
                             "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos",
                             "AB2_Desastres_Hidrológicos_Deslizamento_de_terra")) 
correlacao1 <- cor_matrix %>% 
  pivot_longer(cols = 1:(length(cor_matrix)-1), names_to = "Linha", values_to = "Valores") %>% 
  ggplot(aes(x= Linha, y = Coluna, fill = Valores)) + 
  geom_tile()

correlacao1

rm(cor_matrix, correlacao1)
```

Como é possível observar, a maioria das variáveis não tem um nível de correlação muito elevado, exceto as da mesma categoria do Índice de Risco Climático.

```{r}
#Checando missing values:

colSums(is.na(df_stm))
```

Como é possível observar, temos 14 cidades com Missing Values para a receita. Estes municípios terão que ser removidos da seleção para fazer a análise.\

## 4.3 Rodando a regressão com série temporal

### 4.3.1 Análise com todas as variáveis

```{r}
library(stargazer)

df_stm <- pdata.frame(df_stm, index = c("Cod_IBGE_Mun", "Ano_Mes"))
table(index(df_stm), useNA = "ifany")
#Primeito modelo: agenda mensurada como percentual com menção a termos climáticos

modelo2 <- plm(N_PLsClima ~ lag(N_PLsClima) + 
                 Desastre + lag(Desastre) + Obitos + lag(Obitos) + 
                 dias_proxima_eleicao +  
                 Receitas_pCap + n_OSCs +
                 AB2_Recursos_Hídricos_Seca + 
                 AB2_Segurança_Alimentar_Seca + AB2_Segurança_Alimentar_Chuva +
                 AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos +
                 AB2_Desastres_Hidrológicos_Deslizamento_de_terra, 
               data = df_stm, model = "pooling", pooling = T)

stargazer(modelo2, type = "text")
summary(modelo2)
```

### Visualizando os resultados

```{r}
# Extrair coeficientes e erros padrão diretamente do objeto plm
coefs <- modelo2$coefficients
variaveis <- names(coefs)
estimativas <- coefs

# Extrair erros padrão da matriz de variâncias-covariâncias
erros_padrao <- sqrt(diag(modelo2$vcov))

# Calcular p-valores (opcional, com base na distribuição normal)
t_values <- estimativas / erros_padrao
pvalores <- 1.96 * (1 - pnorm(abs(t_values)))

# Definir nível de significância
nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                 labels = c("***", "**", "*", ".", " "))

# Construir data.frame
m2_plot <- data.frame(
  Variavel = factor(variaveis, levels = variaveis), # manter a ordem
  Estimativa = estimativas,
  Erro_Padrao = erros_padrao,
  IC_inferior = estimativas - 1.96 * erros_padrao,
  IC_superior = estimativas + 1.96 * erros_padrao,
  Significancia = nivel_sig
)

# Remover intercepto para focar nos preditores
#m1_plot <- subset(m1_plot, Variavel != "(Intercept)")

# Plot com ggplot2
M2plot <- ggplot(m1_plot, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  geom_hline(yintercept = 0, color = "black") +
  scale_color_manual(values = c("***"="#6E0000", "**"="#CB8400", "*"="#FFD028", "."="#F7FF00", " "="gray"),
                     name = "Nível de\nSignificância") +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "bottom")+
  labs(
    title = "Modelo 1 - Coeficientes (95%)",
    x = "Variável",
    y = "Estimativa"
  )

M2plot

rm(coefs, variaveis, estimativas, erros_padrao, t_values, pvalores, nivel_sig)
```

```{r}
TestePesaran2 <- pcdtest(modelo2, test = "cd")
print(TestePesaran2)

rm(TestePesaran2)
```

```{r}
#Teste de Durbin-Watson:
TesteDW2 <- pdwtest(modelo2)

print(TesteDW2)

rm(TesteDW2)
```
