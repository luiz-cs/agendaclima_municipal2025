---
title: "4. Análise do efeito dos ECEs sobre a agenda"
output: html_notebook
---

# 4. Análise do efeito dos ECEs sobre a agenda

Agora que já identificamos quais os tópicos dos documentos, vamos fazer uma análise da produção em relação ao total da produção.\
\
Na primeira, faremos a análise com toda a produção que menciona os termos procurados. Na segunda, vamos nos restringir à produção em projetos de lei

## Pacotes e bases de dado

```{r}
#install.packages("patchwork")
#install.packages("plm")
#install.packages("zoo")
#install.packages("collapse")
#install.packages("performance")
```

```{r, echo = FALSE, warning=FALSE}
library(dplyr)
library(here)
library(tidyr)
library(data.table)
library(stringr)
library(ggplot2)
library(lubridate)
library(patchwork)
library(scales)
library(plm)
library(stargazer)
library(zoo)
library(collapse)
library(performance)
```

```{r, echo = FALSE}
df_ols <- readRDS(here("Dados/df_ols.RDS")) 

df_ols[, Dia := as.integer(Dia)]

```

## 4.1 Observando as características da série

### 4.1.1 Distribuição da agenda climática

```{r}
#Heatmap
#Limpar datas:

datas <- df_ols %>% 
  group_by(Data) %>%
  summarise(n = n()) %>% 
  filter(n == max(n))
  
df_heatmap <- df_ols %>% 
  filter(Data %in% datas$Data) %>% 
  mutate(Cod_Reg = str_sub(Cod_IBGE_Mun, 1, 1),
         Regiao = case_when(
           Cod_Reg == 1 ~ "Norte",
           Cod_Reg == 2 ~ "Nordeste",
           Cod_Reg == 3 ~ "Sudeste",
           Cod_Reg == 4 ~ "Sul",
           Cod_Reg == 5 ~ "Centro-Oeste"),
         log_agenda_clima = log1p(agenda_clima))

df_desastres <- df_heatmap %>% 
  filter(Desastre == 1)

regioes <- df_heatmap %>% 
  select(Cod_Reg, Regiao) %>% 
  unique()

# Geração + salvamento dos plots
heatmaps1 <- lapply(c(1:5), function(reg) {
  dados_reg <- df_heatmap %>% filter(Cod_Reg == reg)
  dados_desastres <- dados_reg %>% filter(Desastre == 1)
  Regiao <- regioes %>% 
    filter(Cod_Reg == reg) %>% 
    select(Regiao)

  p <- ggplot(dados_reg, aes(x = Data, y = Cod_IBGE_Mun)) +
    geom_tile(aes(fill = log_agenda_clima)) +
    geom_tile(data = dados_desastres, aes(fill = NULL), color = "red") +
    scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
    theme_classic() +
    theme(
      legend.position = "none",
      axis.title.x = element_blank(),
      axis.title.y = element_blank()
    ) +
    ggtitle(paste("Percentual de Agenda Climática: Região ", Regiao))

  # Salvar
  ggsave(
    filename = here(paste0("Figuras/4.1.", reg, "heatmap_regiao_", Regiao, ".png")),
    plot = p,
    width = 10, height = 4 + n_distinct(dados_reg$Cod_IBGE_Mun) / 20)

  return(p)  # opcional, se quiser reusar depois
})

rm(heatmaps1, datas, df_heatmap, df_desastres, regioes)
```

## 4.1.2 Padronizando as variáveis explicativas

```{r}

#Transformando variável "Obitos" em dummy
df_ols[, "d2_obitos" := fifelse(Obitos >0, 1, 0)]

#Padronizando variáveis contínuas
varpadronizar <- c(
  "Receitas_pCap", "n_OSCs",
  "AB2_Segurança_Alimentar_Seca", "AB2_Segurança_Alimentar_Chuva",
  "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos",
  "AB2_Desastres_Hidrológicos_Deslizamento_de_terra"
)

# Loop eficiente para criar colunas _pd e dp_
for (var in varpadronizar) {
  desvio <- sd(df_ols[[var]], na.rm = TRUE)
  media  <- mean(df_ols[[var]], na.rm = TRUE)
  
  df_ols[[paste0("dp_", var)]] <- desvio
  df_ols[[paste0(var, "_pd")]] <- (df_ols[[var]] - media) / desvio
}

#Criando "meses_proxima_eleicao"
df_ols[, meses_proxima_eleicao := as.integer(time_length(interval(Data, proxima_eleicao), unit = "months"))]

rm(varpadronizar, media, var, desvio)
```

```{r}
#Renomeando variáveis
df_ols <- df_ols %>% 
  rename("y_agenda_clima" = "agenda_clima", "y2_agenda_estrita" = "agenda_estrita",
         "d1_Desastre" = "Desastre",
         "w_dias_eleicao" = "dias_proxima_eleicao", 
         "w2_meses_proxima_eleicao" = "meses_proxima_eleicao",
         "x1_Receitas_pCap_pd" = "Receitas_pCap_pd", 
         "x2_n_OSCs_pd" = "n_OSCs_pd",
    "z1_Seca_pd" = "AB2_Segurança_Alimentar_Seca_pd",
         "z2_Chuva_pd" = "AB2_Segurança_Alimentar_Chuva_pd",
         "z3_Inundacoes_pd" = "AB2_Desastres_Hidrológicos_Inundações_enxurradas_e_alagamentos_pd",
         "z4_Deslizamento_pd" = "AB2_Desastres_Hidrológicos_Deslizamento_de_terra_pd")
```

## 4.2 Testando as condições da variável destino para análise de séries temporais

### 4.2.1 Analisando a variável destino

```{r}
#Teste de estacionariedade
# Gráfico ACF
png(here("Figuras/4.2.1Correlograma1.png"), width = 1200, height = 400)
psacf(df_ols, y_agenda_clima ~ Cod_IBGE_Mun, ~ Dia,
      type = "correlation",
      main = "Correlograma ACF da agenda_clima",
      family = "serif")
dev.off()
```

```{r}
# Gráfico PACF
png(here("Figuras/4.2.2Correlograma_Parcial.png"), width = 1200, height = 400)
psacf(df_ols, y_agenda_clima ~ Cod_IBGE_Mun, ~ Dia,
      type = "partial",
      main = "Correlograma PACF da agenda_clima",
      family = "serif")
dev.off()

```

### 4.2.3 Checando por autocorrelação nas variáveis

```{r, warning=FALSE}
#Checando por autocorrelações na matriz das variáveis: 

cor_matrix <- cor(df_ols[, c("y_agenda_clima", "y2_agenda_estrita", 
                             "d1_Desastre", "d2_obitos",
                             "w_dias_eleicao", "x1_Receitas_pCap_pd", "x2_n_OSCs_pd",
                             "z1_Seca_pd", "z2_Chuva_pd","z3_Inundacoes_pd","z4_Deslizamento_pd")],
                  use = "complete.obs") %>% 
  data.table() %>% 
  mutate(Coluna = c("y_agenda_clima", "y2_agenda_estrita",
                    "d1_Desastre", "d2_obitos",
                             "w_dias_eleicao","x1_Receitas_pCap_pd", "x2_n_OSCs_pd",
                    "z1_Seca_pd", "z2_Chuva_pd","z3_Inundacoes_pd","z4_Deslizamento_pd")) 
correlacao1 <- cor_matrix %>% 
  pivot_longer(cols = 1:(length(cor_matrix)-1), names_to = "Linha", values_to = "Valores") %>% 
  ggplot(aes(x= Linha, y = Coluna, fill = Valores)) + 
  geom_tile()+
    labs(
    title = "Matriz de correlação das variáveis",
    x = "Variáveis 2",
    y = "Variáveis 1",
    caption = "Elaborado pelo autor") +
  theme_classic() +
    theme(legend.position = "bottom",
        text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1))
  

correlacao1


ggsave(here("Figuras/4.2.3Matriz_Correlação.png"), correlacao1, width = 10, height = 10)
rm(cor_matrix, correlacao1)
```

Como é possível observar, a maioria das variáveis não tem um nível de correlação muito elevado, exceto as da mesma categoria do Índice de Risco Climático.

## 4.2.4 Checando balanceamento

```{r}
#Criando coluna separado dos desvios-padrão originais:

desvios <- df_ols %>% 
  select(starts_with("dp")) %>%
  unique() %>% 
  pivot_longer(cols = starts_with("dp"), names_prefix = "dp_", names_to = "Variável", values_to = "Desvio-Padrão Original")

#Checando missing values:

df_ols <- df_ols %>% 
  select(Cod_IBGE_Mun, Dia, Data, Mes, Ano,
         y_agenda_clima, y2_agenda_estrita,
         d1_Desastre, d2_obitos,
         w_dias_eleicao, w2_meses_proxima_eleicao, x1_Receitas_pCap_pd, x2_n_OSCs_pd,
         z1_Seca_pd, z2_Chuva_pd,z3_Inundacoes_pd,z4_Deslizamento_pd)

colSums(is.na(df_ols))
```

Faltam 5833 observações para a variável de Receita. Vamos verificar quais são os municípios faltantes:

```{r}
Receitas_NA <- df_ols %>% 
  mutate(n = ifelse(is.na(x1_Receitas_pCap_pd), 1, 0)) %>% 
    group_by(Cod_IBGE_Mun, Ano) %>% 
  summarise(missing = sum(n)) %>% 
  filter(missing > 0)

nome_munics <- readRDS(here("Dados/df_agendaclima_municipal.RDS")) %>% 
  select(Cod_IBGE_Mun, Nome_Municipio, UF) %>% 
  unique()

Receitas_NA <- merge(Receitas_NA, nome_munics, by = "Cod_IBGE_Mun", all.x = T)

```

Como é possível observar, temos 14 cidades com Missing Values para a receita. Como o número de observações faltantes corresponde a menos de 0,5% das observações, e o foco da análise está na variação agregada, optei opor imputar os dados faltantes.

```{r}

# Ordenando os dados
setkey(df_ols, Cod_IBGE_Mun, Dia)

# Realizando a imputação>
df_ols[, x1_Receitas_pdi := na.approx( #Interpolação
  x1_Receitas_pCap_pd,
  x = Dia,
  na.rm = FALSE,
  rule = 2 #Extrapolação
), by = Cod_IBGE_Mun]

colSums(is.na(df_ols))


rm(nome_munics, Receitas_NA)
```

## 4.3 Rodando a regressão com série temporal

### 4.3.1 Análise com todas as variáveis - Modelo Pooling

```{r}
#Preparando base de dados 
df_ols <- df_ols %>% 
  pdata.frame(index = c("Cod_IBGE_Mun", "Dia"))

```

### Modelo 1: Pooling

```{r}

#Primeito modelo: agenda mensurada como percentual com menção a termos climáticos

modelo1 <- plm(y_agenda_clima ~ lag(y_agenda_clima) + 
                 d1_Desastre + lag(d1_Desastre) + 
         d2_obitos + lag(d2_obitos)+
         w_dias_eleicao+ x1_Receitas_pCap_pd+ x2_n_OSCs_pd+
         z1_Seca_pd+ z2_Chuva_pd + z3_Inundacoes_pd + z4_Deslizamento_pd,
         data = df_ols, model = "pooling")

stargazer(modelo1, type = "text", mean.sd = TRUE)
```

### Visualizando os resultados

```{r, warning=FALSE}
# Extrair coeficientes e erros padrão diretamente do objeto plm
coefs <- modelo1$coefficients
variaveis <- names(coefs)
estimativas <- coefs

# Extrair erros padrão da matriz de variâncias-covariâncias
erros_padrao <- sqrt(diag(modelo1$vcov))

# Calcular p-valores (opcional, com base na distribuição normal)
t_values <- estimativas / erros_padrao
pvalores <- 1.96 * (1 - pnorm(abs(t_values)))

# Definir nível de significância
nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                 labels = c("0,1%***", "1%**", "5%*", "10%.", " "))

# Construir data.frame
m1_plot <- data.frame(
  Variavel = factor(variaveis, levels = variaveis), # manter a ordem
  Estimativa = estimativas,
  Erro_Padrao = erros_padrao,
  IC_inferior = estimativas - 1.96 * erros_padrao,
  IC_superior = estimativas + 1.96 * erros_padrao,
  Significancia = nivel_sig
)

# Remover intercepto para focar nos preditores
#m1_plot <- subset(m1_plot, Variavel != "(Intercept)")

# Plot com ggplot2
M1plot <- ggplot(m1_plot, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  geom_hline(yintercept = 0, color = "black") +
  scale_color_manual(values = c("0,1%***"="#6E0000", "1%**"="#CB8400", "5%*"="#FFD028", "10%."="#F7FF00", " "="gray"),
                     name = "Nível de\nSignificância") +
  coord_flip() +
  theme_bw() +
    theme(legend.position = "bottom",
        text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(
    title = "Coeficientes Modelo 1 (Pooled)",
    x = "Variável",
    y = "Estimativa",
    caption = "Elaborado pelo autor")+
    scale_y_continuous(labels = label_percent(accuracy = 1))

M1plot

ggsave(here("Figuras/4.3.1.1Modelo1.png"), M1plot, width= 10, height = 5)

rm(variaveis, estimativas, erros_padrao, t_values, pvalores, nivel_sig, m1_plot)
```

```{r, warning=FALSE}
M1plot_z <- M1plot+ scale_y_continuous(labels = label_percent(accuracy = 0.001), limits = c(-0.0025, 0.005))

M1plot_z

ggsave(here("Figuras/4.3.1.2Modelo1_zoom.png"), M1plot_z, width= 10, height = 5)

rm(M1plot, M1plot_z)
```

### Teste de autocorrelação nas unidades (Pesaran)

```{r}

TestePesaran1 <- pcdtest(modelo1, test = "cd")
print(TestePesaran1)

saveRDS(TestePesaran1, here("Dados/PesaranM1.RDS"))

rm(TestePesaran1)
```

### Teste de autocorrelação serial de Durbin-Watson

```{r}
#Teste de Durbin-Watson:
TesteDW1 <- pdwtest(modelo1)

print(TesteDW1)

saveRDS(TesteDW1, here("Dados/M1DurbinWatson.RDS"))

rm(TesteDW1)
```

### Teste de Breusch-Godfrey para autocorrelação serial com "pbgtest"

```{r}
# Teste de Breusch-Godfrey com "pbgtest"

#ESTE TESTE EXIGE ELEVADO PODER COMPUTACIONAL. RODE LEVANDO ISSO EM CONTA
#TesteBG <- pbgtest(modelo1)


#TesteBG

#rm(TesteBG)
```

### Efeito de longo prazo da ocorrência de desastres

```{r}
# Long-term effect
lte_total <- (coefs["d1_Desastre"] + coefs["lag(d1_Desastre)"]) / (1 - coefs["lag(y_agenda_clima)"])


print(paste("Efeito de Longo Prazo do Desastre:", round(lte_total, 3), " ou ", round(lte_total/mean(df_ols$y_agenda_clima), 3), "vezes a média de proposituras")) 

rm(lte_total, coefs)
```

### 4.3.2 - Modelo de Efeitos Fixos "Within"

```{r}
#Segunda modelo: agenda mensurada como percentual com menção a termos climáticos, dentro dos municípios

modelo2 <- plm(y_agenda_clima ~ lag(y_agenda_clima) + 
                 d1_Desastre + lag(d1_Desastre) + 
         d2_obitos + lag(d2_obitos)+
         w_dias_eleicao+ x1_Receitas_pCap_pd+ x2_n_OSCs_pd+
         z1_Seca_pd+ z2_Chuva_pd + z3_Inundacoes_pd + z4_Deslizamento_pd,
         data = df_ols, model = "within", effect = "twoway")

summary(modelo2)
stargazer(modelo2, type = "text")
```

### Visualizando os resultados

```{r, warning=FALSE}
# Extrair coeficientes e erros padrão diretamente do objeto plm
coefs2 <- modelo2$coefficients
variaveis <- names(coefs2)
estimativas <- coefs2

# Extrair erros padrão da matriz de variâncias-covariâncias
erros_padrao <- sqrt(diag(modelo2$vcov))

# Calcular p-valores (opcional, com base na distribuição normal)
t_values <- estimativas / erros_padrao
pvalores <- 1.96 * (1 - pnorm(abs(t_values)))

# Definir nível de significância
nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                 labels = c("0,1%***", "1%**", "5%*", "10%.", " "))

# Construir data.frame
m2_plot <- data.frame(
  Variavel = factor(variaveis, levels = variaveis), # manter a ordem
  Estimativa = estimativas,
  Erro_Padrao = erros_padrao,
  IC_inferior = estimativas - 1.96 * erros_padrao,
  IC_superior = estimativas + 1.96 * erros_padrao,
  Significancia = nivel_sig
)

# Remover intercepto para focar nos preditores
#m1_plot <- subset(m1_plot, Variavel != "(Intercept)")

# Plot com ggplot2
M2plot <- ggplot(m2_plot, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  geom_hline(yintercept = 0, color = "black") +
  scale_color_manual(values = c("0,1%***"="#6E0000", "1%**"="#CB8400", "5%*"="#FFD028", "10%."="#F7FF00", " "="gray"),
                     name = "Nível de\nSignificância") +
  coord_flip() +
  theme_bw() +
    theme(legend.position = "bottom",
        text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(
    title = "Coeficientes Modelo 2 (Efeitos Fixos)",
    x = "Variável",
    y = "Estimativa",
    caption = "Elaborado pelo autor")+
    scale_y_continuous(labels = label_percent(accuracy = 1))
M2plot

ggsave(here("Figuras/4.3.2.1Modelo2-FETW.png"), M2plot, width= 10, height = 5)

rm(variaveis, estimativas, erros_padrao, t_values, pvalores, nivel_sig, M2plot, m2_plot)
```

### Teste de autocorrelação nas unidades (Pesaran)

```{r}

TestePesaran2 <- pcdtest(modelo2, test = "cd")
print(TestePesaran2)

rm(TestePesaran2)
```

### Teste de autocorrelação serial de Durbin-Watson

```{r}
#Teste de Durbin-Watson:
TesteDW2 <- pdwtest(modelo2)

print(TesteDW2)

rm(TesteDW2)
```

```{r}
# Long-term effect
lte_total <- (coefs2["d1_Desastre"] + coefs2["lag(d1_Desastre)"]) / (1 - coefs2["lag(y_agenda_clima)"])


print(paste("Efeito de Longo Prazo do Desastre:", round(lte_total, 3), " ou ", round(lte_total/mean(df_ols$y_agenda_clima), 3), "vezes a média de proposituras")) 

rm(lte_total, coefs2)
```

### Comparando os dois modelos

```{r}
stargazer(modelo1, modelo2,  type = "text")
```

## 4.4 Teste com agenda climática estrita

Agora, vamos repetir a análise, utilizando apenas os projetos identificados na segunda modelagem de tópicos como condizentes com a agenda em adaptação climática.

```{r}

#Preparando segunda base de dados
#Retornando para data.table
setDT(df_ols)
#Ajustando variável de tempo Ano-Mês
df_ols[, Ano_Mes := paste0(Ano, "-", fifelse(Mes < 10, as.character(paste0(0, Mes)), as.character(Mes)))]
#Resumindo a base de dados
df_ols <- df_ols[
  , .(
    y2_agenda_estrita = sum(y2_agenda_estrita),
    d1_Desastre = fifelse(sum(d1_Desastre) >= 1, 1, 0),
    d2_obitos = fifelse(sum(d2_obitos) >= 1, 1, 0),
    w2_meses_proxima_eleicao = as.integer(mean(w2_meses_proxima_eleicao)),
    x2_n_OSCs_pd = min(x2_n_OSCs_pd),
    x1_Receitas_pdi = mean(x1_Receitas_pdi)),
  by = .(Cod_IBGE_Mun, Ano_Mes, Mes, Ano,
         z1_Seca_pd, z2_Chuva_pd, 
         z3_Inundacoes_pd, z4_Deslizamento_pd)]

#Alterando a variável mês para ser categórica
df_ols[, Mes := fifelse(Mes < 10, as.character(paste0(0, Mes)), as.character(Mes))]
```

### 4.4.1 Heatmap - Agenda estrita

```{r}
#Heatmap 2 
#Limpar datas:

  
df_heatmap <- df_ols %>% 
  mutate(Cod_Reg = str_sub(Cod_IBGE_Mun, 1, 1),
         Regiao = case_when(
           Cod_Reg == 1 ~ "Norte",
           Cod_Reg == 2 ~ "Nordeste",
           Cod_Reg == 3 ~ "Sudeste",
           Cod_Reg == 4 ~ "Sul",
           Cod_Reg == 5 ~ "Centro-Oeste"))%>% 
  arrange(desc(Cod_IBGE_Mun))


df_desastres <- df_heatmap %>% 
  filter(d1_Desastre == 1) %>% 
  arrange(desc(Cod_IBGE_Mun))

regioes <- df_heatmap %>% 
  ungroup() %>% 
  select(Cod_Reg, Regiao) %>% 
  unique()

# Geração + salvamento dos plots
heatmaps2 <- lapply(c(1:5), function(reg) {
  dados_reg <- df_heatmap %>% filter(Cod_Reg == reg)
  dados_desastres <- dados_reg %>% filter(d1_Desastre == 1)
  Regiao <- regioes %>% 
    filter(Cod_Reg == reg) %>% 
    select(Regiao)

  p <- ggplot(dados_reg, aes(x = Ano_Mes, y = Cod_IBGE_Mun)) +
    geom_tile(aes(fill = y2_agenda_estrita)) +
    geom_tile(data = dados_desastres, aes(fill = y2_agenda_estrita), color = "red", size = 0.25) +
    scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white", limits = c(0, 5)) +
    theme_classic() +
    theme(
      legend.position = "bottom",
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
              text = element_text(family = "Times New Roman", size = 8),
    ) +  
    scale_x_discrete(breaks = function(x) x[seq(1, length(x), by = 6)])+
    ggtitle(paste("Produção de Políticas Climáticas: Região ", Regiao))+
    labs(caption = "Elaborado pelo autor",
         fill = "Nº de projetos climáticos")

  # Salvar
  ggsave(
    filename = here(paste0("Figuras/4.4.", reg, "PLheatmap_regiao_", Regiao, ".png")),
    plot = p,
    width = 10, height = 4 + n_distinct(dados_reg$Cod_IBGE_Mun) / 20)

  return(p) 
})

rm(heatmaps2, datas, df_heatmap, df_desastres, regioes)
```

### 4.4.3 Testes de sazonalidade

```{r, warning = FALSE}

sazonalidade2 <- df_ols %>% 
  group_by(Cod_IBGE_Mun, Mes) %>% 
  summarise(y2_agenda_estrita = sum(y2_agenda_estrita)) %>% 
  group_by(Mes) %>% 
  summarise(y2_agenda_estrita = mean(y2_agenda_estrita)) %>% 
  ggplot(aes(x = Mes, y = y2_agenda_estrita)) +
  geom_col(fill = "darkgreen")+
  theme_bw()+
  labs(title = "Média de produção legislativa relacionada ao clima, por mês",
       x= "Mês", 
       y = "Média de Projetos Climáticos",
       caption = "Elaborado pelo autor")+
    theme(legend.position = "bottom",
        text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 14))

sazonalidade2

ggsave(here("Figuras/4.4.2Sazonalidade2.png"), sazonalidade2, width = 10, height = 4)

rm(sazonalidade2)
```

```{r}
#Checando missing values:

colSums(is.na(df_ols))
```

### 4.4.6 Rodando os modelo para a agenda climática estrita

```{r, warning = FALSE}
#Preparando base de dados 
df_ols <- df_ols %>% 
  pdata.frame(index = c("Cod_IBGE_Mun", "Ano_Mes"))

#Primeito modelo: agenda mensurada como percentual com menção a termos climáticos

mPL1 <- plm(y2_agenda_estrita ~ lag(y2_agenda_estrita) + 
                 d1_Desastre + lag(d1_Desastre) + 
         d2_obitos + lag(d2_obitos)+
         w2_meses_proxima_eleicao + x1_Receitas_pdi + x2_n_OSCs_pd+
         z1_Seca_pd+ z2_Chuva_pd + z3_Inundacoes_pd + z4_Deslizamento_pd+
           Mes,
         data = df_ols, model = "pooling")

mPL2 <- plm(y2_agenda_estrita ~ lag(y2_agenda_estrita) + 
                 d1_Desastre + lag(d1_Desastre) + 
         d2_obitos + lag(d2_obitos)+
         w2_meses_proxima_eleicao + x1_Receitas_pdi + x2_n_OSCs_pd+
         z1_Seca_pd+ z2_Chuva_pd + z3_Inundacoes_pd + z4_Deslizamento_pd+
           Mes,
         data = df_ols, model = "within", effect = "twoway")


stargazer(mPL1, mPL2, type = "text")
```

### Visualizando os resultados

```{r, warning=FALSE}
extrair_plot_df <- function(modelo, nome_modelo) {
  coefs <- modelo$coefficients
  erros_padrao <- sqrt(diag(modelo$vcov))
  t_values <- coefs / erros_padrao
  pvalores <- 1.96 * (1 - pnorm(abs(t_values)))
  
  nivel_sig <- cut(pvalores, breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), 
                   labels = c("0,1%***", "1%**", "5%*", "10%.", " "))
  
  data.frame(
    Variavel = factor(names(coefs), levels = rev(names(coefs))),  # inverter ordem para facet
    Estimativa = coefs,
    Erro_Padrao = erros_padrao,
    IC_inferior = coefs - 1.96 * erros_padrao,
    IC_superior = coefs + 1.96 * erros_padrao,
    Significancia = nivel_sig,
    Modelo = nome_modelo
  )
}

# Gerar data.frames
m1_plot <- extrair_plot_df(mPL1, "M3: Pooled")
m2_plot <- extrair_plot_df(mPL2, "M4: Efeitos Fixos")

# Unir os dois
plot_data <- rbind(m1_plot, m2_plot)

# Verificar quais variáveis aparecem apenas no modelo Pooled
variaveis_por_modelo <- table(plot_data$Variavel, plot_data$Modelo)

so_no_mPL1 <- names(which(variaveis_por_modelo[, "M3: Pooled"] == 1 & rowSums(variaveis_por_modelo) == 1))

plot_data <- subset(plot_data, !(Variavel %in% so_no_mPL1 & Significancia == " "))


# Plot
coef_plot <- ggplot(plot_data, aes(x = Variavel, y = Estimativa, color = Significancia)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_pointrange(aes(ymin = IC_inferior, ymax = IC_superior)) +
  scale_color_manual(
    values = c("0,1%***" = "#6E0000", "1%**" = "#CB8400", "5%*" = "#FFD028", 
               "10%." = "#F7FF00", " " = "gray"),
    name = "Nível de\nSignificância"
  ) +
  coord_flip() +
  theme_bw(base_family = "Times New Roman") +
  facet_grid(cols = vars(Modelo)) +
  labs(
    title = "Comparação de Coeficientes: Modelos Pooled vs Efeitos Fixos",
    x = "Variável",
    y = "Efeito Estimado",
    caption = "Elaborado pelo autor"
  ) +
    theme(legend.position = "bottom",
        text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 14))

# Visualizar
print(coef_plot)

# Salvar
ggsave(here("Figuras/4.4.6Modelos3_4.png"), coef_plot, width = 10, height = 10)

rm(coef_plot, extrair_plot_df, m1_plot, m2_plot, variaveis_por_modelo, so_no_mPL1, plot_data)
```

### Efeitos de Longo Prazo

```{r}
coefs3 <- mPL1$coefficients

# Desastre
lte_total <- (coefs3["d1_Desastre"] + coefs3["lag(d1_Desastre)"]) / (1 - coefs3["lag(y2_agenda_estrita)"])


print(paste("Efeito de Longo Prazo do Desastre:", round(lte_total, 3), " ou ", round(lte_total/mean(df_ols$y2_agenda_estrita), 3), "vezes a média de proposituras")) 

#Óbitos
lte_total <- (coefs3["d2_obitos"] + coefs3["lag(d2_obitos)"]) / (1 - coefs3["lag(y2_agenda_estrita)"])


print(paste("Efeito de Longo Prazo dos Óbitos:", round(lte_total, 3), " ou ", round(lte_total/mean(df_ols$y2_agenda_estrita), 3), "vezes a média de proposituras")) 

rm(lte_total, coefs3)
```

### Testes Modelo 3

```{r}
TestePesaran3 <- pcdtest(mPL1, test = "cd")
print(TestePesaran3)

rm(TestePesaran3)
```

```{r}
#Teste de Durbin-Watson:
TesteDW3 <- pdwtest(mPL1)

print(TesteDW3)

rm(TesteDW3)
```

```{r}
# Teste de Breusch-Godfrey com "pbgtest"

TesteBG3 <- pbgtest(mPL1)


TesteBG3

rm(TesteBG3)
```

### Testes Modelo 4

```{r}
TestePesaran4 <- pcdtest(mPL2, test = "cd")
print(TestePesaran4)

rm(TestePesaran4)
```

```{r}
#Teste de Durbin-Watson:
TesteDW4 <- pdwtest(mPL2)

print(TesteDW4)

rm(TesteDW4)
```

```{r}
# Teste de Breusch-Godfrey com "pbgtest"

TesteBG4 <- pbgtest(mPL2)


TesteBG4

rm(TesteBG4)
```

Este documento encerra a análise deste projeto. Qualquer problema ou dúvida, entrar em contato com luiz.cs\@alumni.usp.br
